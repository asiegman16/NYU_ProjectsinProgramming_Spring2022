{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Raw Cell Format",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Class6_unsolved.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1rYXzJLpJGS"
      },
      "source": [
        "# Natural Language Processing with spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TdfW65mpJGU"
      },
      "source": [
        "Today we are going to learn about NLP (Natural Language Processing) using spaCy, an open source library for advanced NLP. \n",
        "\n",
        "For more on spaCy, you can check out their site: https://spacy.io/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "w5DgQXLrpJGV"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwCL45EqpJGZ"
      },
      "source": [
        "Natural Language Processing (NLP) is a subfield of Artificial Intelligence that deals with the 'understanding' of language. \n",
        "\n",
        "For the purposes of this tutorial, we are going to look at the very basics of NLP, including using spaCy, an open-source NLP library. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3U2q8-tpJGa"
      },
      "source": [
        "from spacy.lang.en import English # import the English language class\n",
        "\n",
        "nlp = English() # create an nlp object; this object contains the processing pipeline, which you \n",
        "                # ultimately use to analyze the text\n",
        "    \n",
        "doc = nlp(\"Hello world!\") # \"Hello world!\" becomes the text that we want to analyze\n",
        "                          # when you process a text with the nlp object, spaCy creates a Doc object\n",
        "    \n",
        "for token in doc: # for every token in our Doc object (a token being a word or character)...\n",
        "    print(token.text) # simply print out that token "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Az2OPxZpJGc"
      },
      "source": [
        "## Indexing\n",
        "\n",
        "Similar to how you index through a list in Python, you can index through a Doc to retreive tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koSez6H6pJGd"
      },
      "source": [
        "# doc\n",
        "# doc[1].text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t5K7L1ypJGg"
      },
      "source": [
        "## Spans\n",
        "\n",
        "You can also use 'span' which lets you take a slice of the Doc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_9nGLjypJGg"
      },
      "source": [
        "# span"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXvSsRXtpJGj"
      },
      "source": [
        "## What else can we do with spaCy? \n",
        "\n",
        "Tokens have lots of attributes associated with them! For instance: \n",
        "\n",
        "1. is_alpha returns boolean indicating if a token consists of an alphanumeric value\n",
        "2. is_punct returns boolean indicating if a token is punctuation\n",
        "3. like_num returns boolean indicating if a token resembles a number \n",
        "\n",
        "These are all called \"lexical attributes\" – they refer to the entry in the vocabulary and don't depend on the token's context. (More on that later). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J07gURfjpJGj"
      },
      "source": [
        "doc = nlp(\"The earnings report will be released at 5 pm sharp.\") # the text we want to work with \n",
        "\n",
        "print('Index: ', [token.i for token in doc]) # i being the index of the token in the Doc\n",
        "print('Text: ', [token.text for token in doc]) # return the text of the token\n",
        "\n",
        "print(\" \") # just so we have some nice spacing in our results below...\n",
        "\n",
        "print('is_alpha:', [token.is_alpha for token in doc]) # if token consists of an alphanumeric value\n",
        "print('is_punct:', [token.is_punct for token in doc]) # if token is punctuation\n",
        "print('like_num:', [token.like_num for token in doc]) # if token resembles a number (e.g., '10' or 'TEN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW-WLPLNwhl4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "Cl5dInjNwhl_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvmEFNfPwhmA"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3aa28vlpJGm"
      },
      "source": [
        "# Exercise 1:\n",
        "\n",
        "Imagine you are charged with reporting on a long press release, and you just want to know where in the document a percent increase or percent decrease is mentioned..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8WOQyqRpJGn"
      },
      "source": [
        "doc = nlp(\"In 2012, earnings were hovering around 60%, verus in 2019 where they are less than 4% – a 93% decrease.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bEST5CDpJGq"
      },
      "source": [
        "Use next_token, .like_num, .text, and find any percentage value mentiond in the doc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFGeMx_kpJGq"
      },
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXwgBoeepJGr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Slk9OD8ztC"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "RjXVNtdF8ztD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybb1uleu8ztD"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ygs3MP9pJGu"
      },
      "source": [
        "## Pre-Built Models:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7Tjw54WxpJGu"
      },
      "source": [
        "import spacy \n",
        "\n",
        "nlp = spacy.load('en') # loading in the package we just downloaded...\n",
        "\n",
        "doc = nlp(\"Adidas AG and Gap Inc. are among those at the end of the long supply chain that travel through \\\n",
        "           China’s northwest region of Xinjiang.\") # this is the text we want to analyze \n",
        "                                                   # that '\\' above just lets me split the text into a new \n",
        "                                                   # line in my notebook, and isn't part of the text itself\n",
        "\n",
        "for token in doc: # for each token in our Doc...\n",
        "    print(token.text, token.pos_, token.dep_, token.head.text) # print the following:\n",
        "    \n",
        "    # .pos_ will give us the parts of speech for each token\n",
        "    # .dep_ will give us the predicted dependency label \n",
        "    # .head.text will give us the 'syntactic head token' (think of it as the parent token this word is attached to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_smVjsGbpJGw"
      },
      "source": [
        "## `ent.label_`\n",
        "\n",
        "Can be used to decipher entities..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1Xx0vxppJGx"
      },
      "source": [
        "# ent.label_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkhLiz0pJGz"
      },
      "source": [
        "## `.explain`\n",
        "\n",
        "Can be used to get quick definitions of common tags and labels, you can use \".explain\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qhDfNC-pJG0"
      },
      "source": [
        "# .explain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ_3TJl09Csn"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "JxKhXiDP9Cso"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2USwo0e9Cso"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv_FJguSpJG2"
      },
      "source": [
        "spaCy also lets you write rules to find words and/or phrases in a text. Similar to Regular Expressions, but with some major benefits unique to spaCy. \n",
        "\n",
        "In particular, it allows you to match on Doc objects (not just strings), use the model's prediction capabilities, and match on tokens and token attributes. Match patterns in spaCy are comprised of lists of dictionaries, and each dictionary describes one token. \n",
        "\n",
        "The keys in the dictionary are the names of the token attributes, and are mapped to their expected value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb3ZF4fopJG3"
      },
      "source": [
        "doc = nlp(\"New iPhone X release date leaked as Apple reveals pre-orders by mistake.\") # our text\n",
        "\n",
        "from spacy.matcher import Matcher # import the matcher\n",
        "matcher = Matcher(nlp.vocab) # initialize the matcher\n",
        "\n",
        "pattern = [{'TEXT':'iPhone'}, {'TEXT':'X'}]    # match these exact token texts\n",
        "\n",
        "matcher.add('IPHONE_PATTERN', None, pattern) # add the pattern to the matcher\n",
        "\n",
        "matches = matcher(doc) # call the matcher on our Doc and store the result as a list called 'matches'\n",
        "\n",
        "print(matches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx77DRmGpJG5"
      },
      "source": [
        "You'll note that the matcher returns a list of tuples. Each tuple (an immutable list of fixed size) consists of three values: \n",
        "\n",
        "    1. The match ID\n",
        "    2. The start index of the matched span\n",
        "    3. The end index of the matched span\n",
        "    \n",
        "Fortunately, we can iterate over our matches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT1LHC_opJG5"
      },
      "source": [
        "# iterate over matches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrjqmLYppJG8"
      },
      "source": [
        "Remember, you can also match on lexical attributes and token attributions. For instance, below we are going to look for five tokens: \n",
        "\n",
        "1. A token consisting of only digits\n",
        "2. Two, case-insensitive tokens for the words \"revenue\" and \"up\"\n",
        "3. Another token that consists of only digits\n",
        "4. A punctuation token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPuFhRgJpJG8"
      },
      "source": [
        "# pattern"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yofyfog9Ha9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "itwa_MI49Ha9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzvpC0Kq9Ha9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsgBRhpRpJG_"
      },
      "source": [
        "## A note on Operators and Quantifiers.\n",
        "\n",
        "Operators and Quantifiers let you define how often a token should be matched. \n",
        "\n",
        "An Operator can have one of four values: \n",
        "\n",
        "1. An \"!\" negates the token, so it's matched 0 times\n",
        "2. A \"?\" makes the token optional, so it matches 0 or 1 times\n",
        "3. A \"+\" matches a token 1 or more times\n",
        "4. A \"*\" matches a token 0 or more times\n",
        "\n",
        "Below, the \"?\" Operator makes the determiner token optional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_sbJMSQpJHA"
      },
      "source": [
        "# matcher"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XD81Ac5pJHC"
      },
      "source": [
        "## Luckily, Spacy also allows us to use Regular Expressions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MFqope9pJHC"
      },
      "source": [
        "# matcher with regex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcTnpKN69Os8"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "DSOdk4SK9Os8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7H8pcha9Os9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw7W4rappJHF"
      },
      "source": [
        "# Exercise 2\n",
        "\n",
        "Using the text provided below, create a pattern match that finds any news about a possible merger or acquisition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPbs2-6EpJHF"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hji0DrApJHH"
      },
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbtJ01jipJHI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiJ6BJvY9QyW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "ZDtlQdrP9QyX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvMbke8-9QyX"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll-RSr8ypJHK"
      },
      "source": [
        "## Vocabularies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-SST8H6pJHK"
      },
      "source": [
        "spaCy stores all shared data in a vocabulary, which includes words, as well as the labeled schemas for tags and entities. It also uses a hash function to generate an ID for each string, which is stored in a string store and is available via nlp.vocab.strings\n",
        "\n",
        "This string store is ultimately a lookup table whereby you can look up a string to get its hash, or, look up a hash to get the string. For instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62WXJ47rpJHL"
      },
      "source": [
        "# hash values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Dh6U1HpJHN"
      },
      "source": [
        "spaCy even lets you compare two objects to predict how similar they are. \n",
        "\n",
        "These objects can be documents, spans, or single tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2f6gT7PpJHN"
      },
      "source": [
        "# similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPrrDliRpJHP"
      },
      "source": [
        "We can also compare two tokens: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etLLMQUVpJHQ"
      },
      "source": [
        "# similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8kVi_G0pJHS"
      },
      "source": [
        "# similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRu4fyUHpJHV"
      },
      "source": [
        "Or, a document with a token: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDcP93b5pJHV"
      },
      "source": [
        "# similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Far9hBuJpJHY"
      },
      "source": [
        "And, last but not least, a span with a document: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6fwR22dpJHY"
      },
      "source": [
        "# similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lc_2PS-9T9B"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "D7NQdY1k9T9C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaAqRAaT9T9C"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAjpkvc9pJHb"
      },
      "source": [
        "## BeautifulSoup + spaCy\n",
        "\n",
        "Now, let's use some of the BeautifulSoup to analyze some text from an online source:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQLya7G9pJHb"
      },
      "source": [
        "import time\n",
        "import re\n",
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "r = requests.get('https://www.vice.com/en_us/article/a35ve5/what-it-would-take-for-the-next-president-to-cancel-all-student-debt') \n",
        "    # for more on the requests library check out this tutorial from RealPython: \n",
        "    # https://realpython.com/python-requests/\n",
        "            \n",
        "soup = BeautifulSoup(r.text,'html') # we are going to turn that URL into 'soup', aka, we are going to be \n",
        "                                    # able to see it's metadata For more on BeautifulSoup, check out: \n",
        "                                    # https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
        "            \n",
        "print(soup)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xUSqc62pJHd"
      },
      "source": [
        "We know that what we're interested in is the text of this article. So, let's see what that looks like in the HTML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qMhvcjCpJHd"
      },
      "source": [
        "# paragraphs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "psdLTDtNpJHf"
      },
      "source": [
        "# article"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-3hOt5-9XA_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "IBsL8Ehz9XA_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6Vb-8ut9XA_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDd0Bx5DpJHi"
      },
      "source": [
        "# Exercise 3:\n",
        "\n",
        "What if we want to know what entities are mentioned in the article? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvkMpzKypJHi"
      },
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q6kN-VppJHi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynMKccI3pJHk"
      },
      "source": [
        "# Exercise 4:\n",
        "\n",
        "What if we want to know the similarity between the first and last sentences of the aritcle? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQD5bksqpJHl"
      },
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ1AaaX8pJHl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7URuKdVe9ffp"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "t1ee1NF69ffp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StsL7DUN9ffp"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsZjgdW1pJHn"
      },
      "source": [
        "An enormous thank you to spaCy, whose existing online courses (https://course.spacy.io/chapter1) were the basis for this Jupyter-ized tutorial. For more information on spaCy's existing online course, check out https://github.com/ines/spacy-course#-faq"
      ]
    }
  ]
}