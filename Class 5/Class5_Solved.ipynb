{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Class5_Solved.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3Va3omEkRUT"
      },
      "source": [
        "# Web Scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf4eF3jJkRUV"
      },
      "source": [
        "There is a LOT of useful information onthe internet, and as data scientists you'll often need access to that information. \n",
        "\n",
        "Unfortunatley, rarely is that information contained neatly in CSVs or even in tabular form. Rather, you have to really work to get what you need. \n",
        "\n",
        "Lucky for us, there are some useful tools for \"scraping\" the web – in particular, one called [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFem0_PbkRUW",
        "scrolled": true
      },
      "source": [
        "import time\n",
        "import re\n",
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "!pip install lxml #https://lxml.de/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2LBai7gkRUZ"
      },
      "source": [
        "## `BeautifulSoup`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv6AjaojkRUZ"
      },
      "source": [
        "url = \"https://www.nytimes.com/news-event/coronavirus\" \n",
        "\n",
        "r = requests.get(url) # the requests library is the easiest way to call to a URL; here we are using a GET command\n",
        "\n",
        "soup = BeautifulSoup(r.text,'html') # we are going to take the result of that GET command and pass it through bs4\n",
        "\n",
        "print(soup.prettify()) # 'prettify' does exactly what you'd think – it prettifies the output of the print statement"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gudQ3KrEkRUd"
      },
      "source": [
        "What you're seeing above is the HTML for the NYT homepage. Let's continue with a few basics:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omh7KTHSkRUd"
      },
      "source": [
        "## `soup.title` \n",
        "\n",
        "Finds the title of a page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoIg6Xn5kRUe"
      },
      "source": [
        "soup.title "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao_xps8akRUh"
      },
      "source": [
        "## `soup.title.string`\n",
        "\n",
        "Gets a string version of that same title "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk7vYuJukRUh"
      },
      "source": [
        "soup.title.string "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFtweQqjkRUn"
      },
      "source": [
        "## `soup.p`\n",
        "\n",
        "Get the first paragraph tag in the HTML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64RZWSjckRUo"
      },
      "source": [
        "soup.p "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "978OxOWDkRUr"
      },
      "source": [
        "soup.p['class'] # get the class of that <p> tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2njk13l1kRUu"
      },
      "source": [
        "## `soup.find_all`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYEYfaPqkRUx"
      },
      "source": [
        "soup.find_all('p') # let's find all p class tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfDBfAeXX28k"
      },
      "source": [
        "url = \"https://www.nytimes.com/2020/10/01/business/economy/layoffs-unemployment-claims.html\" \n",
        "\n",
        "r = requests.get(url) # the requests library is the easiest way to call to a URL; here we are using a GET command\n",
        "\n",
        "soup = BeautifulSoup(r.text,'html') # we are going to take the result of that GET command and pass it through bs4"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIlIAHdZZBj2"
      },
      "source": [
        "soup.title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znEiAQ3gX_sh"
      },
      "source": [
        "soup.title.string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohMpsSUrYA4S"
      },
      "source": [
        "content = soup.find_all('p')\n",
        "\n",
        "content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DFPVgY2d-Ho"
      },
      "source": [
        "content_list = []\n",
        "\n",
        "for p in content:\n",
        "  content_list.append(p.string)\n",
        "  \n",
        "article = content_list[2:40]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEi03gl0hi59"
      },
      "source": [
        "article"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyHDO4SKgKF_"
      },
      "source": [
        "for i in article: \n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW-WLPLNwhl4"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "Cl5dInjNwhl_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvmEFNfPwhmA"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErmOFA_QkRV6"
      },
      "source": [
        "# RSS Feeds\n",
        "\n",
        "An RSS ('Real Simple Syndication') feed is nothing more than a text file that is updated with information (usually pared down) from a website. For more, check out [this article by Digital Trends](https://www.digitaltrends.com/computing/what-is-an-rss-feed/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVSoIOXdkRV6"
      },
      "source": [
        "In order to flex our RSS Feed skills we are going to be mimicking this brilliant and simple bot, [@TwoHeadlines](https://twitter.com/twoheadlines?lang=en) <br> \n",
        "\n",
        "<br>\n",
        "\n",
        "The concept is simple. It takes two different headlines from two different outlets via their RSS feeds (which we'll go over in a moment) and combines them to produce often comical and almost always nonsensical news headlines.\n",
        "\n",
        "<br>\n",
        "\n",
        "The first thing we must do to create our own TwoHeadlines bot is import a few libraries. Remember, libraries in Python are collections of functions and methods that allow you to perform various actions without writing your own code.\n",
        "\n",
        "<br>\n",
        "\n",
        "For instance, in our Two Headlines bot we are going to use: \n",
        "\n",
        "#### Feedparser: a library that will allow us to read various RSS feeds (again, we'll get to RSS in a moment)<br>\n",
        "https://pythonhosted.org/feedparser/introduction.html\n",
        "\n",
        "#### Random: a library that will allow us to generate random numbers <br> \n",
        "https://docs.python.org/2/library/random.html\n",
        "\n",
        "#### Time: a library that will allow us to work around traditionally tricky time functions <br>\n",
        "https://docs.python.org/2/library/time.html\n",
        "\n",
        "<br>\n",
        "\n",
        "Thus, your first lines of code will look as follows: <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n84tz19okRV6"
      },
      "source": [
        "!pip install feedparser\n",
        "\n",
        "import feedparser\n",
        "import random\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41c6LtCCkRV8"
      },
      "source": [
        "<br> Great! Now, we want to begin by defining our function. <br>\n",
        "\n",
        "Remember, funcitons come in handy when you want to repeat the same task many times using the same _type_ of input. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXg-i2p1kRV-"
      },
      "source": [
        "# for example\n",
        "\n",
        "def printSentence(sentence):\n",
        "    print(sentence + \" Plus a new sentence.\")\n",
        "    return;"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wdst0SxkRWA"
      },
      "source": [
        "printSentence(\"This is the sentence I want to print.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbfbE3qAkRWC"
      },
      "source": [
        "In this case, we will call our function 'TwoHeadlines' \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVFyycOLkRWC"
      },
      "source": [
        "def TwoHeadlines(): # we are leaving the input blank for now, and you'll see why in a moment\n",
        "    pass            # this 'pass' is here just to avoid an error as we work on our function. To see what happens without it, \n",
        "                    # try removing the 'pass' line and see the error you receive."
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezRmZ0H_kRWE"
      },
      "source": [
        "To best understand what you can get from an RSS feed, take a look at the following examples: \n",
        "\n",
        "http://www.wsj.com/public/page/rss_news_and_feeds.html <br>\n",
        "https://archive.nytimes.com/www.nytimes.com/services/xml/rss/index.html <br>\n",
        "http://rss.cnn.com/rss/cnn_topstories.rss <br>\n",
        "\n",
        "To see how you can actually pull these RSS feeds using Python, we're going to rely on Python. As an example, let's pull two feeds.\n",
        "\n",
        "Note that we first set a variable equal to the desired url for the desired RSS feed. Then, we use feedparser to store that information into a new variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KomIottkkRWF"
      },
      "source": [
        "nyt_rss_url = 'https://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml' # find the desired rss feed\n",
        "espn_rss_url = 'https://www.espn.com/espn/rss/news' # find a second desired rss feed\n",
        "\n",
        "nyt_feed = feedparser.parse(nyt_rss_url) # use feedparser to, well, parse the feed\n",
        "espn_feed = feedparser.parse(espn_rss_url) # use feedparser to, well, parse the feed"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6coVTISkRWH"
      },
      "source": [
        "Next, we need to get a bit creative, because we don't want that entire RSS feed; We just want the headline for the latest article! But if you type the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QviQ-LokRWH"
      },
      "source": [
        "print(nyt_feed) # print the full RSS feed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t5A8mKzkRWI"
      },
      "source": [
        "for i in range(0,10): # for the first ten entries in the RSS feed (the ten most recent stories)\n",
        "    print(nyt_feed['entries'][i]['title']) # print the title of said article"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDvgeQSIzNuM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "iJJ7QPrYzNuM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7ARdS4dzNuM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myfGv2KfkRWL"
      },
      "source": [
        "But how did we know to use \"['entries'][i]['title']\"?\n",
        "\n",
        "To understand, we need to briefly delve into the world of dictionaries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQiu0ffakRWL"
      },
      "source": [
        "dictionary = {'favorite_food':'pasta'} # create a new dictionary \n",
        "\n",
        "# consider 'favorite_food' to be the word, and 'pasta' to be the definition, it it helps you"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GApW2gnbkRWM"
      },
      "source": [
        "print(dictionary['favorite_food'])\n",
        "\n",
        "# we then call 'favorite_food' and get the \"definiton\" \n",
        "# in reality, this is known as a Key:Value pair, with \"Key\" being the word, and \"Value\" being the definition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B6bP3pvkRWO"
      },
      "source": [
        "As you may be able to see, our RSS is actually formated quite cleverily. It is a dicitionary (a set of key-value pairs) that includes lists. For example, look at the very top of the feed. It starts \n",
        "\n",
        "#### {'feed': {'title': 'WSJ.com: World News',\n",
        "\n",
        "The best way to read this is - the first entry in the dictionary is 'Feed' and the first value for that entry (also known as a 'key' is 'Title'. \n",
        "\n",
        "Now, 'Title' happens to be another dictionary (you can tell because it begins with a '{'). If we keep searching, we'll see that the headline comes after 'entries' and is paired with the 'title'. \n",
        "\n",
        "I know this is all exceptionally confusing, but just bear with me. The more you practice parsing information from RSS feeds (or HTML in general) the easier it will become, I promise!\n",
        "\n",
        "So, if we want that headline, and that headline only, we are going to: \n",
        "\n",
        "1. Navigate to the entire RSS feed\n",
        "2. Navigate to the 'entries' section\n",
        "3. Navigate to the first 'entries' section (each story is going to have its own, and we want the first headline)\n",
        "4. Navigate to the 'title' section \n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTbUBjZUkRWO"
      },
      "source": [
        "Now, back to replicating 'TwoHeadlinesBot'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg6KPhNjkRWO"
      },
      "source": [
        "my_list = [] # create a new, empty list called 'my_list'\n",
        "\n",
        "for i in range(0,10): \n",
        "    my_list.append(nyt_feed['entries'][i]['title']) # append the first ten titles to this list"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjjZtZWDkRWQ"
      },
      "source": [
        "my_list[3] # select the third index of that list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJCd3lXRkRWT"
      },
      "source": [
        "Article4 = my_list[3]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K981K9MkRWV"
      },
      "source": [
        "Article4[:25] # get the first 25 characters of the title of the 3rd index (fourth article) in our list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5iA9T6kkRWX"
      },
      "source": [
        "len(Article4) # how many characters long is our title? "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__7AtxbpkRWY"
      },
      "source": [
        "len(Article4)/2 # figure out the half-way point of the title "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjCq5ZXtkRWa"
      },
      "source": [
        "Article4[0:30] # get the first half of our article title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Fs6AUgMkRWb"
      },
      "source": [
        "Article5 = my_list[4] # let's see what the next title is in our list\n",
        "print(Article5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQQ-g11LzQQx"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "2hEW8PnEzQQx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_Xa7WmDzQQx"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "L6yxbHl1kRWd"
      },
      "source": [
        "So, how do we want to mash our headlines together?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yokdboZQkRWd"
      },
      "source": [
        "nyt_first_story = nyt_feed['entries'][0]['title'] #Recall that '0' is actually the first instance\n",
        "print(nyt_first_story)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8Pj7ot0kRWe"
      },
      "source": [
        "words = nyt_first_story.split(' ') # remember, I can split that single sentence into a list of individual words \n",
        "print(words) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlRlPJzEkRWg"
      },
      "source": [
        "for i in range(0,10): \n",
        "\n",
        "    nyt_first_story = nyt_feed['entries'][i]['title'] # pull the title of the ith story in the first RSS feed\n",
        "    espn_first_story = espn_feed['entries'][i]['title'] # pull the title of the ith story in the second RSS feed\n",
        "\n",
        "    nyt_words = nyt_first_story.split(' ') # split the title by spaces (aka, make every word in the title it's own)\n",
        "    espn_words = espn_first_story.split(' ') # split the title by spaces (aka, make every word in the title it's own)\n",
        "    \n",
        "print(nyt_words) \n",
        "print(\" --- \") # print a line for formatting purposes\n",
        "print(espn_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miNajJrWkRWi"
      },
      "source": [
        "Let's keep going. Remember, we want to take half of one headline and half of a different headline and mash them together. So, how do we get just the first or second half of a list of words?  <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_o4gQwikRWi"
      },
      "source": [
        "for i in range(0,10): \n",
        "\n",
        "    nyt_first_story = nyt_feed['entries'][i]['title'] # pull the title of the ith story in the first RSS feed\n",
        "    espn_first_story = espn_feed['entries'][i]['title'] # pull the title of the ith story in the second RSS feed\n",
        "\n",
        "    nyt_words = nyt_first_story.split(' ') # split the title by spaces (aka, make every word in the title it's own)\n",
        "    espn_words = espn_first_story.split(' ') # split the title by spaces (aka, make every word in the title it's own)\n",
        "\n",
        "    nyt_words = nyt_words[:int(len(nyt_words)/2)] \n",
        "    espn_words = espn_words[int(len(espn_words)/2):]\n",
        "    \n",
        "print(nyt_words)\n",
        "print(\" --- \")\n",
        "print(espn_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he9dY3XEzTUQ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⭕ **QUESTIONS?**"
      ],
      "metadata": {
        "id": "j6t4WRTyzTUQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aiqn3FFzzTUR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j3te4sZkRWm"
      },
      "source": [
        "## Walkthrough of our Code\n",
        "\n",
        "1) First, the `[:`    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOnDU3n-kRWm"
      },
      "source": [
        "# the ':' at the front of a list means 'everything leading up to this point. For instance: \n",
        "\n",
        "list = ['a','b','c','d','e']\n",
        "list = list[:3]\n",
        "print(list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtCZcGH8kRWo"
      },
      "source": [
        "In other words, we want to print everything leading up to (but not including!) the third instance in our list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaXX7qAHkRWo"
      },
      "source": [
        " 2)  Next, the `int` allows us to ensure we're working with integers so we can do the necessary division at the end of the line of code.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNzoNER0kRWo"
      },
      "source": [
        "len(nyt_words)/2 # the result is a float, which we don't want"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvii6_BwkRWq"
      },
      "source": [
        "int(len(nyt_words)/2) # tis gives us an integer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX8BmlO5kRWr"
      },
      "source": [
        "3)  `len` is a function that gives you the number of items in a list. For instance: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02JYbHl_kRWr"
      },
      "source": [
        "list = ['a','b','c','d','e']\n",
        "len(list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H29-1sWqkRWt"
      },
      "source": [
        "4) Finally, we are taking the total number of words in the headline and dividing by two"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEIprf9FkRWt"
      },
      "source": [
        "In total, we are saying: \"Take the headline, find out how many words are in the headline and divide by two. Then, take the first half of that headline and store it as the new healdine.\" \n",
        "\n",
        "_Note that while for the first healdine we take the first half (by putting the ':' at the beginning of the code) we are taking the second half of the second headline (by putting the ':' at the end of the code)._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0455_iD9kRWt"
      },
      "source": [
        "## All together, now\n",
        "\n",
        "Finally, we want to join the two halves of our healdine and store it as the variable 'new_headline' "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPCexKvVkRWt"
      },
      "source": [
        "for i in range(0,10): \n",
        "\n",
        "    nyt_first_story = nyt_feed['entries'][i]['title'] # pull the title of the ith story in the first RSS feed\n",
        "    espn_first_story = espn_feed['entries'][i]['title'] # pull the title of the ith story in the second RSS feed\n",
        "\n",
        "    nyt_words = nyt_first_story.split(' ') # split the title by spaces (aka, make every word in the title it's own)\n",
        "    espn_words = espn_first_story.split(' ') # split the title by spaces (aka, make every word in the title it's own)\n",
        "\n",
        "    nyt_words = nyt_words[:int(len(nyt_words)/2)] \n",
        "    espn_words = espn_words[int(len(espn_words)/2):]\n",
        "    \n",
        "    new_headline = nyt_words + espn_words # Take the first half of the title from the first RSS feed and add the second half of the second RSS feed\n",
        "    new_headline = ' '.join(new_headline) # Join the two strings created above with spaces\n",
        "\n",
        "    print(new_headline) # Print your newly created headline"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}